{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comunicados de Política Monetaria\n",
    "## Parte 2.\n",
    "\n",
    "En este notebook crearemos un pandas DataFrame con las decisiones de política monetaria de Banxico y haremos un análisis de la información recabada.\n",
    "\n",
    "Unicamente pandas y numpy, matplotlib, seaborn Con la información obtenida modelar Naive Bayes, si un documento dado pertenece a la clase 'mantien,sube y baja'\n",
    "\n",
    "Paso:\n",
    "\n",
    "*Descargar pdfs\n",
    "\n",
    "*Limpiar los datos \n",
    "\n",
    "*Eliminar de todos los archivos las palabras que contengan 'mantiene, incrementa, disminuye'. \n",
    "\n",
    "*Parte los documentos entre un set de entrenamiento (0.8) y uno de prueba (0.2) \n",
    "\n",
    "*Entrena el modelo con los documentos de entrenamiento y valida el resultado con una matriz de confusión usando la base de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from requests_html import HTMLSession\n",
    "from unidecode import unidecode\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "from PyPDF4 import PdfFileReader\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2008-02-15', '2008-03-14', '2008-04-18', '2008-05-16',\n",
       "               '2008-06-20', '2008-07-18', '2008-08-15', '2008-09-19',\n",
       "               '2008-10-17', '2008-11-28',\n",
       "               ...\n",
       "               '2018-12-20', '2019-02-07', '2019-03-28', '2019-05-16',\n",
       "               '2019-06-27', '2019-08-15', '2019-09-26', '2019-11-14',\n",
       "               '2019-12-19', '2020-02-13'],\n",
       "              dtype='datetime64[ns]', name='date', length=106, freq=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se obtienen los datos generados por la parte 1 desde el archivo pkl.\n",
    "comunicados = pd.read_pickle('comunicados-banxico.pkl')\n",
    "comunicados.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_pdf(serie):\n",
    "    \"\"\"\n",
    "    Función para descargar lop PDFs usando como base el Pandas DataFrame genererado en la parte 1\n",
    "    \"\"\"\n",
    "    for link,date,page in zip(serie.url,serie.index,tqdm(range(len(serie)))):\n",
    "        Pdf=\"Comunicado-\"+str(date)[:10]+\".pdf\"\n",
    "        with HTMLSession() as sess:\n",
    "            r = sess.get(link)\n",
    "        if not os.path.exists(\"descargas\"):\n",
    "            os.mkdir(\"descargas\")\n",
    "        full_path = os.path.join(\"descargas\", Pdf)\n",
    "        with open(full_path, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        sleep(0.5)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63278728ecfc4926842430c599640053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=106.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download_pdf(comunicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_information(pdf_path):\n",
    "    \"\"\"\n",
    "    Función para estraer el contenido de un PDF\n",
    "    \"\"\"\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        content = \"\"\n",
    "        pdf = PdfFileReader(f)\n",
    "        for i in range(0, pdf.getNumPages()):\n",
    "            content += pdf.getPage(i).extractText() + \"\\n\"\n",
    "            content = \" \".join(content.replace(\"\\n\", \"\").strip().split())\n",
    "            content = \" \".join(word.strip(string.punctuation) for word in content.split() if word.isalpha())\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1801]\n"
     ]
    }
   ],
   "source": [
    "textos = {}\n",
    "\n",
    "# Con base en el Pandas DataFrame que se generó en la parte 1, se obtienen los contenidos de\n",
    "# cada PDF descargado usando la funsión extract_information() y se guardan en un diccionario\n",
    "\n",
    "for date,text in zip(comunicados.index, comunicados.text):\n",
    "    archivo=os.path.join(\"descargas\", \"Comunicado-\"+str(date)[:10]+\".pdf\")\n",
    "    info=extract_information(archivo)\n",
    "    category = re.search(\"(mantiene|incrementa|disminuye)\",text).group(1)\n",
    "    textos.setdefault(category, [])\n",
    "    textos[category].append(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{nums: len(textos) for nums,textos in textos.items()}\n",
    "def limpia_texto (textox):\n",
    "    \"\"\"\n",
    "    Función que quita las stopwords, signos de puntuacion y números entregando una lista de palabras\n",
    "    \"\"\"\n",
    "    all_stopwords = [unidecode(word) for word in stopwords.words('spanish')]\n",
    "    sw_list = ['mantiene','incrementa','disminuye']\n",
    "    all_stopwords.extend(sw_list)\n",
    "    textox = \" \".join(word.strip(string.punctuation) for word in textox.split() if word.isalpha())\n",
    "    text_tokens = word_tokenize(textox.lower())\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
    "    return tokens_without_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se genera cada uno de los arrieglos por clase de documento de acuerdo a la llave del diccionario que los contiene\n",
    "K1,K2,K3 = \"mantiene\",\"incrementa\",\"disminuye\"\n",
    "D1 = [texto for texto in textos[K1]]\n",
    "D2 = [texto for texto in textos[K2]]\n",
    "D3 = [texto for texto in textos[K3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se generan dos sub arreglos por cada unade las clases con los parámetros requeridos \n",
    "D1_train, D1_test = train_test_split(D1, test_size=0.2)\n",
    "D2_train, D2_test = train_test_split(D2, test_size=0.2)\n",
    "D3_train, D3_test = train_test_split(D3, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mayo', 'comunicado', 'prensa', ..., 'ciento', 'hacia', 'finales'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se limpias el texto dejándolo como arreglo de palabras contenidas para cada una de las clases de textos\n",
    "D1_train = np.concatenate([limpia_texto(text) for text in D1_train ])\n",
    "D2_train = np.concatenate([limpia_texto(text) for text in D2_train ])\n",
    "D3_train = np.concatenate([limpia_texto(text) for text in D3_train ])\n",
    "D1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mantiene</th>\n",
       "      <th>incrementa</th>\n",
       "      <th>disminuye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ajustadas</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>exhiba</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mantendrá</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.001051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>terremotos</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>significante</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>respecto</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.001840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>observarán</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>detectado</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>procesos</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sustancialmente</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>conviene</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>desalineados</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ajustes</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.000526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comunicado</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.002103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>normalización</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.000263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>implementar</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dejaron</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>derivadas</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>registrándose</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tras</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mantiene  incrementa  disminuye\n",
       "ajustadas        0.000075    0.000282   0.000131\n",
       "exhiba           0.000075    0.000094   0.000131\n",
       "mantendrá        0.001611    0.000658   0.001051\n",
       "terremotos       0.000075    0.000094   0.000131\n",
       "significante     0.000075    0.000094   0.000131\n",
       "respecto         0.002960    0.002350   0.001840\n",
       "observarán       0.000075    0.000094   0.000131\n",
       "detectado        0.000037    0.000282   0.000131\n",
       "procesos         0.000075    0.000094   0.000131\n",
       "sustancialmente  0.000112    0.000094   0.000131\n",
       "conviene         0.000262    0.000094   0.000131\n",
       "desalineados     0.000037    0.000188   0.000131\n",
       "ajustes          0.001236    0.001316   0.000526\n",
       "comunicado       0.003522    0.003383   0.002103\n",
       "normalización    0.000787    0.000846   0.000263\n",
       "implementar      0.000075    0.000094   0.000131\n",
       "dejaron          0.000075    0.000094   0.000131\n",
       "derivadas        0.000412    0.000282   0.000263\n",
       "registrándose    0.000150    0.000188   0.000131\n",
       "tras             0.000075    0.000094   0.000131"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se genera un Pandas DataFrame con los diccionarios de aprendizaje y la probabilidad de cada palabra en la cada clase de documento\n",
    "dictionary = pd.DataFrame(index=(set(D1_train) | set(D2_train)| set(D3_train)))\n",
    "dictionary = (dictionary.join(pd.Series(D1_train, name='mantiene').value_counts(),how='left')\n",
    "                        .join(pd.Series(D2_train, name='incrementa').value_counts(),how='left')\n",
    "                        .join(pd.Series(D3_train, name='disminuye').value_counts(),how='left'))\n",
    "dictionary = dictionary.fillna(0)+1\n",
    "dictionary = dictionary / dictionary.sum(axis=0)\n",
    "dictionary.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42220974, -1.5422443 , -2.03635928])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se obtienes las probabilidades apriori\n",
    "total = len(D1_train) + len(D2_train) + len(D3_train)\n",
    "log_prior_D1 = np.log(len(D1_train)/total)\n",
    "log_prior_D2 = np.log(len(D2_train)/total)\n",
    "log_prior_D3 = np.log(len(D3_train)/total)\n",
    "log_Priors = np.array([log_prior_D1,log_prior_D2,log_prior_D3])\n",
    "log_Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se realiza la comprobación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de Mantiene:  15 \n",
      "Test de Incrementa 4 \n",
      "Test de Disminuye 4\n"
     ]
    }
   ],
   "source": [
    "# Se imprimen los tamaños de las pruebas\n",
    "print(\"Test de Mantiene: \", len(D1_test), \"\\nTest de Incrementa\", len(D2_test), \"\\nTest de Disminuye\", len(D3_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se generan las matrices para la prueba\n",
    "D_test = D1_test + D2_test + D3_test\n",
    "test = (['mantiene'] * len(D1_test)) + (['incrementa'] * len(D2_test)) + (['disminuye'] * len(D3_test))\n",
    "hat_test = []\n",
    "vocs = set(D1_train) | set(D2_train)| set(D3_train)\n",
    "log_dic = np.log(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Dtest in D_test:\n",
    "    f = set([palabra for palabra in Dtest.split() if palabra in vocs])\n",
    "    res = log_dic.loc[f].sum(axis=0) + log_Priors\n",
    "    hat_test.append(res.idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'incrementa',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'incrementa',\n",
       " 'incrementa',\n",
       " 'incrementa',\n",
       " 'incrementa',\n",
       " 'incrementa',\n",
       " 'mantiene',\n",
       " 'disminuye',\n",
       " 'disminuye',\n",
       " 'disminuye']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'mantiene',\n",
       " 'incrementa',\n",
       " 'incrementa',\n",
       " 'incrementa',\n",
       " 'incrementa',\n",
       " 'disminuye',\n",
       " 'disminuye',\n",
       " 'disminuye',\n",
       " 'disminuye']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  0,  1],\n",
       "       [ 0,  4,  0],\n",
       "       [ 0,  2, 13]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se genera la matriz de confusión\n",
    "confusion_matrix(test, hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Nota: La matriz de confusión, no entiendo por qué, me la entrega invertida, teniendo en la esquina inferior derecha el valor para \"mantiene\" y en la esquina superior izquierda el valor para disminuye"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
